---
tags:
  - technical_library
title: Combining Local Symmetry Exploitation and Reinforcement Learning for Optimised Probabilistic Inference
authors: Sagad Hamid, Tanya Braun
bibtex: "@misc{hamid2025combininglocalsymmetryexploitation,      title={Combining Local Symmetry Exploitation and Reinforcement Learning for Optimised Probabilistic Inference -- A Work In Progress},       author={Sagad Hamid and Tanya Braun},      year={2025},      eprint={2503.08786},      archivePrefix={arXiv},      primaryClass={cs.AI},      url={https://arxiv.org/abs/2503.08786}, }"
pretty_cite:
link: https://doi.org/10.48550/arXiv.2503.08786
topics: Equivariance, Symmetry, Probabilistic Inference, Tensor Networks, Probabilistic Graphical Models, Reinforcement Learning
reading_lists:
projects:
type:
to_read: false
stars:
---

(Very roughly) When doing probabilistic inference, you aim to find the relationships between random variables in a joint distribution. You can "factor" the distribution into independent parts. But the order in which you do this is very important, and affects the computational cost. You can formulate this problem as an MDP, and by grouping together symmetries (variables which can be exchanged? sub-graphs that look the same? (I suppose variables are leaves of the graphs)) you can share computations and solve the problem more efficiently.